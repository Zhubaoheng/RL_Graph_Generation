# generate_planar_dataset.py
import torch
import torch_geometric
import networkx as nx
import os
import sys
from tqdm import tqdm
import numpy as np
from scipy.spatial import Delaunay
from torch_geometric.data import Data, Batch
import torch_geometric.utils

# ==================== ç”¨æˆ·é…ç½® (éœ€è¦æ‚¨ä¿®æ”¹) ====================
# 1. é¡¹ç›® 'src' ç›®å½•çš„ç»å¯¹æˆ–ç›¸å¯¹è·¯å¾„
#    ç›®çš„æ˜¯è®©è„šæœ¬èƒ½æ‰¾åˆ°å¹¶å¯¼å…¥é¡¹ç›®ä¸­çš„ SpectreGraphDataset ç±»
PROJECT_SRC_PATH = "/home/ly/max/DeFoG-swanlab/src"  # <--- å¦‚æœè„šæœ¬ä¸åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼Œè¯·ä¿®æ”¹ä¸ºæ­£ç¡®çš„è·¯å¾„

# 2. æ•°æ®é›†çš„æ ¹ç›®å½•è·¯å¾„ï¼Œç”¨äºåˆ›å»º 'raw' å­ç›®å½•å¹¶ä¿å­˜æ–‡ä»¶
#    è¿™é‡Œä»¥ 'planar' æ•°æ®é›†ä¸ºä¾‹ï¼Œä¸ spectre_dataset.py å…¼å®¹
DATASET_ROOT_DIR = "/home/ly/max/DeFoG-swanlab/data/my_planar"  # <--- ä¿®æ”¹ä¸ºæ‚¨çš„ç›®æ ‡æ•°æ®é›†æ ¹ç›®å½•

# 3. æ•°æ®é›†å¤§å°é…ç½®
TRAIN_GRAPHS = 128  # è®­ç»ƒé›†å›¾çš„æ•°é‡
VAL_GRAPHS = 32     # éªŒè¯é›†å›¾çš„æ•°é‡
TEST_GRAPHS = 40   # æµ‹è¯•é›†å›¾çš„æ•°é‡
NUM_NODES = 128      # Planaræ•°æ®é›†çš„èŠ‚ç‚¹æ•°å›ºå®šä¸º64
# ==============================================================

# --- å°†é¡¹ç›®srcç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„ä¸­ ---
try:
    # ç¡®ä¿è·¯å¾„å­˜åœ¨
    if not os.path.isdir(PROJECT_SRC_PATH):
        raise FileNotFoundError
    sys.path.append(PROJECT_SRC_PATH)

    print("âœ… æˆåŠŸä»é¡¹ç›®ä¸­å¯¼å…¥ SpectreGraphDatasetã€‚")
except (ImportError, FileNotFoundError):
    print(f"âŒ é”™è¯¯: æ— æ³•åœ¨ '{PROJECT_SRC_PATH}' æ‰¾åˆ° 'datasets.spectre_dataset'ã€‚")
    print("è¯·ç¡®ä¿ PROJECT_SRC_PATH æŒ‡å‘äº†æ‚¨é¡¹ç›®çš„ 'src' ç›®å½•ã€‚")
    exit()

def generate_connected_planar_graph(num_nodes: int) -> nx.Graph:
    """ä½¿ç”¨Delaunayä¸‰è§’å‰–åˆ†ç”Ÿæˆä¸€ä¸ªè¿é€šçš„å¹³é¢å›¾ã€‚"""
    while True:
        pos = {i: (np.random.rand(), np.random.rand()) for i in range(num_nodes)}
        points = np.array(list(pos.values()))
        delaunay_tri = Delaunay(points)
        graph = nx.Graph()
        for simplex in delaunay_tri.simplices:
            nx.add_cycle(graph, simplex)
        graph.add_nodes_from(range(num_nodes))
        if nx.is_connected(graph) and len(graph.nodes) == num_nodes:
            return graph

def convert_nx_to_adjacency_matrix(graph: nx.Graph) -> torch.Tensor:
    """
    å°†å•ä¸ª networkx å›¾å¯¹è±¡è½¬æ¢ä¸ºé‚»æ¥çŸ©é˜µã€‚
    è¿™ä¸ªæ ¼å¼ä¸ spectre_dataset.py æœŸæœ›çš„æ ¼å¼ä¸€è‡´ã€‚
    """
    # ä» networkx å›¾è·å–é‚»æ¥çŸ©é˜µ
    adj = torch.Tensor(nx.to_numpy_array(graph))
    return adj

def generate_and_save_datasets(
    node_counts, 
    train_size=TRAIN_GRAPHS, 
    val_size=VAL_GRAPHS, 
    test_size=TEST_GRAPHS, 
    root_dir=DATASET_ROOT_DIR
):
    """
    ç”Ÿæˆè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼Œä¿å­˜ä¸ºé‚»æ¥çŸ©é˜µåˆ—è¡¨æ ¼å¼ã€‚
    è¿™ä¸ªæ ¼å¼ä¸ spectre_dataset.py æœŸæœ›çš„æ ¼å¼å®Œå…¨ä¸€è‡´ã€‚
    
    å‚æ•°:
    - node_counts: æ¯ä¸ªå›¾ä¸­èŠ‚ç‚¹çš„æ•°é‡åˆ—è¡¨
    - train_size: è®­ç»ƒé›†ä¸­æ¯ç§èŠ‚ç‚¹æ•°å›¾çš„æ•°é‡
    - val_size: éªŒè¯é›†ä¸­æ¯ç§èŠ‚ç‚¹æ•°å›¾çš„æ•°é‡
    - test_size: æµ‹è¯•é›†ä¸­æ¯ç§èŠ‚ç‚¹æ•°å›¾çš„æ•°é‡
    - root_dir: ä¿å­˜æ•°æ®é›†çš„æ ¹ç›®å½•
    """
    raw_dir = os.path.join(root_dir, "raw")
    os.makedirs(raw_dir, exist_ok=True)
    print(f"é‚»æ¥çŸ©é˜µæ•°æ®æ–‡ä»¶å°†ä¿å­˜åœ¨ '{raw_dir}/' ç›®å½•ä¸‹ã€‚")

    # ä¸ºæ¯ç§æ•°æ®é›†(è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•)ç”Ÿæˆæ•°æ®
    datasets = {
        'train': train_size,
        'val': val_size,
        'test': test_size
    }

    for dataset_name, dataset_size in datasets.items():
        print(f"\n>>> æ­£åœ¨ç”Ÿæˆ{dataset_name}é›†...")
        adjacency_matrices = []
        
        for n_nodes in node_counts:
            print(f"  æ­£åœ¨ä¸º {n_nodes} ä¸ªèŠ‚ç‚¹çš„å›¾ç”Ÿæˆ {dataset_name} é›†...")
            
            for _ in tqdm(range(dataset_size), desc=f"  ç”Ÿæˆ {n_nodes}-node å¹³é¢å›¾"):
                # 1. ç”Ÿæˆä¸€ä¸ªè¿é€šçš„å¹³é¢å›¾
                nx_graph = generate_connected_planar_graph(n_nodes)

                # 2. è½¬æ¢ä¸ºé‚»æ¥çŸ©é˜µï¼ˆä¸ spectre_dataset.py æœŸæœ›çš„æ ¼å¼ä¸€è‡´ï¼‰
                adj_matrix = convert_nx_to_adjacency_matrix(nx_graph)
                adjacency_matrices.append(adj_matrix)
        
        # 3. ä¿å­˜ä¸ºé‚»æ¥çŸ©é˜µåˆ—è¡¨ï¼ˆä¸ spectre_dataset.py æœŸæœ›çš„æ ¼å¼ä¸€è‡´ï¼‰
        file_path = os.path.join(raw_dir, f"{dataset_name}.pt")
        torch.save(adjacency_matrices, file_path)
        
        print(f"  âœ… å·²æˆåŠŸç”Ÿæˆå¹¶ä¿å­˜ {len(adjacency_matrices)} ä¸ªé‚»æ¥çŸ©é˜µåˆ° '{file_path}'")

if __name__ == "__main__":
    # è¿™é‡Œè®¾ç½®è¦ç”Ÿæˆçš„å›¾çš„èŠ‚ç‚¹æ•°
    # Planaræ•°æ®é›†ä½¿ç”¨å›ºå®šçš„64ä¸ªèŠ‚ç‚¹
    node_list = [NUM_NODES]
    
    print("ğŸš€ å¼€å§‹ç”Ÿæˆ Planar æ•°æ®é›†ï¼ˆä¸ spectre_dataset.py å…¼å®¹çš„æ ¼å¼ï¼‰...")
    generate_and_save_datasets(
        node_counts=node_list,
        train_size=TRAIN_GRAPHS,
        val_size=VAL_GRAPHS,
        test_size=TEST_GRAPHS
    )
    
    print(f"\nğŸ‰ è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†å·²æˆåŠŸç”Ÿæˆï¼")
    print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"   - è®­ç»ƒé›†: {len(node_list) * TRAIN_GRAPHS} å¼ å›¾")
    print(f"   - éªŒè¯é›†: {len(node_list) * VAL_GRAPHS} å¼ å›¾")
    print(f"   - æµ‹è¯•é›†: {len(node_list) * TEST_GRAPHS} å¼ å›¾")
    print(f"âš ï¸  æ•°æ®æ ¼å¼ä¸ spectre_dataset.py å®Œå…¨å…¼å®¹ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ dataset=planar è¿è¡Œã€‚")